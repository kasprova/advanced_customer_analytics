{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_generation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kasprova/advanced_customer_analytics/blob/master/notebooks/feature_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-CwGXANwgu5",
        "colab_type": "text"
      },
      "source": [
        "## FEATURES GENERATION: (update 2019-10-19)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUTWXADYk_8r",
        "colab_type": "text"
      },
      "source": [
        "We have transaction data for 2 years. The first year (Sept 2015 - Aug 2016) data we use for our modeling, the second one we use for validation (Sept 2016 - Aug 2017)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "600_5FV7zrOi",
        "colab_type": "text"
      },
      "source": [
        "### Features types \n",
        "We create a Universe table with the following type of features (monthly aggregation for the period: **Sept 2015 - Aug 2016**):\n",
        "\n",
        "- RFM features \n",
        "- Churn feature\n",
        "- Discount applied/bottle diposites/refund(Number, Total value of Discount)\n",
        "- Categories of Products Purchased - proportion of money spent on a particuler category of products\n",
        "- Loyalty program features (Duration sience start, Number of loyalty cards)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJK6XrbiBJla",
        "colab_type": "code",
        "outputId": "2765e71a-9a1a-46a8-96f6-aa112e1728a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct 14 14:08:22 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYq7NRUkmOnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTNmV7WgmZwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGQI7DlMme79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import pyspark\n",
        "from pyspark import SparkConf\n",
        "conf = SparkConf().setAppName(\"App\")\n",
        "conf = (conf.set('spark.driver.memory', '10G'))\n",
        "\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "from pyspark.sql import SQLContext\n",
        "sql = SQLContext(sc)\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVEjsWu3FIY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSt8X3U2mhOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import dayofmonth, to_date, datediff, length, first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVRiSojVVVby",
        "colab_type": "text"
      },
      "source": [
        "### Mount dataset from Google Disk to Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsuopARqVgb2",
        "colab_type": "code",
        "outputId": "b2660cb3-4ef1-4011-f3dd-127297b8cfac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "#mount google drive to get access to the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMHBc0samwEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q \"drive/My Drive/analytics/DATA.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc_pskYsw3uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "stores = spark.read.parquet(\"stores.parquet\")\n",
        "unique_customers = spark.read.parquet(\"unique_customers.parquet\")\n",
        "transactions = spark.read.parquet(\"transactions.parquet\")\n",
        "categories = spark.read.parquet(\"categories.parquet\")\n",
        "cat_manual = spark.read.parquet(\"cat_manual.parquet\")\n",
        "dim_cal_date = spark.read.parquet(\"dim_cal_date_SB.parquet\")\n",
        "customers = spark.read.parquet(\"clients.parquet\")\n",
        "upc_base = spark.read.parquet(\"upc_base.parquet\")\n",
        "\n",
        "#create views for sql queries\n",
        "stores.createOrReplaceTempView('stores')\n",
        "unique_customers.createOrReplaceTempView('unique_customers')\n",
        "transactions.createOrReplaceTempView('transactions')\n",
        "categories.createOrReplaceTempView('categories')\n",
        "cat_manual.createOrReplaceTempView('cat_manual')\n",
        "dim_cal_date.createOrReplaceTempView('dim_cal_date')\n",
        "customers.createOrReplaceTempView('customers')\n",
        "upc_base.createOrReplaceTempView('upc_base')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXzfM-UZz5Y5",
        "colab_type": "text"
      },
      "source": [
        "#### 1. RFM features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZnQ6P7sygO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define Recency (time of last purchase), Frequency, MonetaryValue\n",
        "fm_features = spark.sql(\"\"\"\n",
        "select \n",
        "    month_id,\n",
        "    household_id, -- link to the address - each household can have a few cards\n",
        "    max(cal_date) as LastPurchase,\n",
        "    count(distinct trans_id) as Frequency,\n",
        "    round(sum(net_sales_amount/100),2) as Monetary --convert from cents to dollars\n",
        "from transactions t\n",
        "    join dim_cal_date cd\n",
        "    on date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "    join customers uc\n",
        "    on uc.card_number = t.card_number\n",
        "    where item_type in (0,20) -- 0 - item purchased, 20 - discard the item, all the rest some coupons/discounts/bottles..\n",
        "    and month_id between 201509 and 201608\n",
        "group by 1,2\n",
        "\"\"\")\n",
        "fm_features.createOrReplaceTempView('fm_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyNNYCDL1cmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding Recency: who pays more than 1 dollar \n",
        "rfm_features = spark.sql(\"\"\"\n",
        "select  c.month_id,\n",
        "        household_id, \n",
        "        datediff(concat(year_id, '-',substring(next_month_id,5,2),'-01'), LastPurchase) as recency, -- max_day +1\n",
        "        frequency,\n",
        "        monetary\n",
        "from fm_features c\n",
        "join dim_cal_date cd \n",
        "    on c.month_id = cd.month_id\n",
        "where Monetary >=1\n",
        "group by 1,2,3,4,5\n",
        "order by 1,2\n",
        "\"\"\")\n",
        "rfm_features.createOrReplaceTempView('rfm_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAceC2QG0Fqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spark.sql(\"\"\"\n",
        "#  select min(local_trans_datetime),\n",
        "#          max(local_trans_datetime)\n",
        "#  from transactions\n",
        "#  \"\"\").show()\n",
        "#+-------------------------+-------------------------+\n",
        "#|min(local_trans_datetime)|max(local_trans_datetime)|\n",
        "#+-------------------------+-------------------------+\n",
        "#|        20150816 00:01:03|        20171029 23:59:21|\n",
        "#+-------------------------+-------------------------+"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HLcFQxERsVZ",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Churn Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLcPUBVYR_8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "churn_feature = spark.sql(\"\"\"\n",
        "select \n",
        "    rfm.month_id,\n",
        "    rfm.household_id, \n",
        "    case when rfm.month_id = LastMonthPurchase and rfm.month_id not in (201608) then 1\n",
        "        else 0 end as churn\n",
        "from rfm_features rfm\n",
        "join (select \n",
        "        household_id, \n",
        "        max(month_id) LastMonthPurchase\n",
        "      from rfm_features\n",
        "      group by 1) x\n",
        "on rfm.household_id = x.household_id \n",
        "\"\"\")\n",
        "churn_feature.createOrReplaceTempView('churn_feature')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6YdAm_A8lz",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Discount applied (Number, Total value of Discount)\n",
        "\n",
        "    3.1 Discounts\n",
        "    3.2 Bottles\n",
        "    3.3 Refunds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjb3c0fAoG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3.1 discounts\n",
        "discount_features = spark.sql(\"\"\"\n",
        "    select month_id,\n",
        "           household_id,\n",
        "           sum(case \n",
        "                   when item_type in (1,21) then discount_number \n",
        "                   else 0\n",
        "               end) as discount_number__store_coupon,\n",
        "           sum(case \n",
        "                   when item_type in (1,21) then discount_value\n",
        "                   else 0\n",
        "               end) as discount_value__store_coupon,\n",
        "           \n",
        "           sum(case \n",
        "                   when item_type in (2,22) then discount_number \n",
        "                   else 0\n",
        "               end) as discount_number__manufacture_coupon,\n",
        "           sum(case \n",
        "                   when item_type in (2,22) then discount_value \n",
        "                   else 0\n",
        "               end) as discount_value__manufacture_coupon,\n",
        "           \n",
        "           sum(case \n",
        "                   when item_type in (3,23) then discount_number \n",
        "                   else 0\n",
        "               end) as discount_number__misc_credit,\n",
        "           sum(case \n",
        "                   when item_type in (3,23) then discount_value \n",
        "                   else 0\n",
        "               end) as discount_value__misc_credit,\n",
        "           \n",
        "           sum(case \n",
        "                   when item_type in (5,25) then discount_number \n",
        "                   else 0\n",
        "               end) as discount_number__prologic_credit,\n",
        "           sum(case \n",
        "                   when item_type in (5,25) then discount_value \n",
        "                   else 0 \n",
        "               end) as discount_value__prologic_credit,\n",
        "           \n",
        "           sum(discount_number) as discount_number__total,\n",
        "           sum(discount_value) as discount_value__total      \n",
        "    from (\n",
        "        select  cd.month_id,\n",
        "                uc.household_id, \n",
        "                item_type,\n",
        "                count(distinct upc) as discount_number,\n",
        "                round(sum(sales_amount/100),2) as discount_value\n",
        "        from transactions t\n",
        "            join dim_cal_date cd\n",
        "            on date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "            join customers uc\n",
        "            on uc.card_number = t.card_number\n",
        "            where item_type in (1,2,3,5,21,22,23,25) \n",
        "            and month_id between 201509 and 201608\n",
        "        group by 1,2,3)x\n",
        "    group by 1,2\n",
        "    order by 1,2\n",
        "\"\"\")\n",
        "discount_features.createOrReplaceTempView('discount_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_mKk16QStn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3.2 bottles\n",
        "bottle_features = spark.sql(\"\"\"\n",
        "    select month_id,\n",
        "           household_id,\n",
        "           sum(case \n",
        "                   when item_type in (9,29) then discount_number \n",
        "                   else 0\n",
        "               end) as deposite_number__bottle,\n",
        "           sum(case \n",
        "                   when item_type in (9,29) then discount_value\n",
        "                   else 0\n",
        "               end) as deposite_value__bottle,\n",
        "           \n",
        "           sum(case \n",
        "                   when item_type in (10,30) then discount_number \n",
        "                   else 0\n",
        "               end) as return_number__bottle,\n",
        "           sum(case \n",
        "                   when item_type in (10,30) then discount_value \n",
        "                   else 0\n",
        "               end) as return_value__bottle    \n",
        "    from (\n",
        "        select  cd.month_id,\n",
        "                uc.household_id, \n",
        "                item_type,\n",
        "                count(distinct upc) as discount_number,\n",
        "                round(sum(sales_amount/100),2) as discount_value\n",
        "        from transactions t\n",
        "            join dim_cal_date cd\n",
        "            on date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "            join customers uc\n",
        "            on uc.card_number = t.card_number\n",
        "            where item_type in (9,29,10,30)\n",
        "            and month_id between 201509 and 201608\n",
        "        group by 1,2,3)x\n",
        "    group by 1,2\n",
        "    order by 1,2\n",
        "\"\"\")\n",
        "bottle_features.createOrReplaceTempView('bottle_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui0haghxS5KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3.3 refund\n",
        "refund_features = spark.sql(\"\"\"\n",
        "    select month_id,\n",
        "           household_id,\n",
        "           sum(case \n",
        "                   when item_type in (7) then discount_number \n",
        "                   else 0\n",
        "               end) as refund_number,\n",
        "           sum(case \n",
        "                   when item_type in (7) then discount_value\n",
        "                   else 0\n",
        "               end) as refund_value  \n",
        "    from (\n",
        "        select  cd.month_id,\n",
        "                uc.household_id, \n",
        "                item_type,\n",
        "                count(distinct upc) as discount_number,\n",
        "                round(sum(sales_amount/100),2) as discount_value\n",
        "        from transactions t\n",
        "            join dim_cal_date cd\n",
        "            on date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "            join customers uc\n",
        "            on uc.card_number = t.card_number\n",
        "            where item_type in (7)\n",
        "            and month_id between 201509 and 201608\n",
        "        group by 1,2,3)x\n",
        "    group by 1,2\n",
        "    order by 1,2\n",
        "\"\"\")\n",
        "refund_features.createOrReplaceTempView('refund_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-L4W-IZBa6f",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Money proportion spend per each category of products (manual categories: 60 categories manually combined into 12)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0uL7ctDBPi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_by_cat_m = spark.sql(\"\"\"\n",
        "    select cd.month_id,\n",
        "           u.household_id,\n",
        "           cm.category_manual,\n",
        "           sum(t.net_sales_amount) sum_paid_amout\n",
        "      from transactions t, customers u, categories c, dim_cal_date cd, cat_manual cm\n",
        "     where t.item_type in (0,20)\n",
        "       and u.card_number = t.card_number\n",
        "       and lpad(c.upc,14,'0') = lpad(t.upc,14,'0')\n",
        "       and date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "       and c.category_id2 is not null\n",
        "       and cm.category = lower(regexp_replace(c.category_desc2,\" \",\"_\"))\n",
        "       and cd.month_id between 201509 and 201608\n",
        "     group by cd.month_id, u.household_id, cm.category_manual       \n",
        "\"\"\")\n",
        "\n",
        "sum_by_cat_m.createOrReplaceTempView(\"sum_by_cat_m\")\n",
        "\n",
        "\n",
        "total_sum = spark.sql(\"\"\"\n",
        "    select cd.month_id,\n",
        "           u.household_id,\n",
        "           sum(net_sales_amount) total_paid_amout\n",
        "      from transactions t, customers u, categories c, dim_cal_date cd\n",
        "     where item_type in (0,20)\n",
        "       and u.card_number = t.card_number\n",
        "       and lpad(c.upc,14,'0') = lpad(t.upc,14,'0')\n",
        "       and date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "       and c.category_id2 is not null\n",
        "       and cd.month_id between 201509 and 201608\n",
        "     group by cd.month_id, u.household_id\n",
        "\"\"\")\n",
        "\n",
        "total_sum.createOrReplaceTempView(\"total_sum\")\n",
        "\n",
        "cat_portion_m = spark.sql(\"\"\"\n",
        "    select d.month_id,\n",
        "           d.household_id,\n",
        "           d.category_manual,\n",
        "           d.sum_paid_amout/t.total_paid_amout cat_portion\n",
        "      from sum_by_cat_m d, total_sum t\n",
        "     where d.household_id = t.household_id\n",
        "         and d.month_id = t.month_id\n",
        "\"\"\")\n",
        "cat_portion_m.createOrReplaceTempView(\"cat_portion_m\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd7DJoUhBgXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_m_portion_features = cat_portion_m.groupBy('month_id','household_id').pivot('category_manual').sum('cat_portion')\n",
        "cat_m_portion_features = cat_m_portion_features.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PAZ6U4yCmKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for c in cat_m_portion_features.columns[2:]:\n",
        "    cat_m_portion_features = cat_m_portion_features.withColumnRenamed(c, 'cat_m_{}_paid_amount_pcnt'.format(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sL5a97mCvM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_m_portion_features.createOrReplaceTempView('cat_m_portion_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVN8UsWiCzfP",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Loyalty program features (Duration sience start,  Number of loyalty cards)\n",
        "Comments: \n",
        "\n",
        "    - duration since start counted in months (difference between registration date and last purchase in a selected month)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pMFOtQnCxp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loyalty_features = spark.sql(\"\"\"\n",
        "    select  cd.month_id,\n",
        "        uc.household_id, \n",
        "        cast((substring(recent_purchase,0,4)-substring(first_shop_date,0,4))*12 +\n",
        "            (substring(recent_purchase,6,2)-substring(first_shop_date,6,2)) as int) as duration_since_start__months,\n",
        "        count(distinct uc.card_number) as cards_number\n",
        "    from transactions t, dim_cal_date cd, customers uc, (  select cd.month_id, \n",
        "                                                        uc.household_id, \n",
        "                                                        max(cal_date) as recent_purchase\n",
        "                                                    from transactions t, dim_cal_date cd, customers uc\n",
        "                                                    where date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "                                                        and uc.card_number = t.card_number\n",
        "                                                        and cd.month_id between 201509 and 201608\n",
        "                                                    group by 1,2) x\n",
        "    where date_format(cd.cal_date,'yyyyMMdd') = substring(t.local_trans_datetime,0,8)\n",
        "        and uc.card_number = t.card_number\n",
        "        and cd.month_id = x.month_id\n",
        "        and uc.household_id = x.household_id\n",
        "        and cd.month_id between 201509 and 201608\n",
        "    group by 1,2,3\n",
        "    order by 1,2\n",
        "\"\"\")\n",
        "loyalty_features.createOrReplaceTempView('loyalty_features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l20h-kA3DsfO",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Create universal feature table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40vpYjTqDi6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#join features together\n",
        "features = spark.sql(\"\"\"\n",
        "    select  distinct \n",
        "            a.month_id,\n",
        "            a.household_id,\n",
        "            a.recency,\n",
        "            a.frequency,\n",
        "            a.monetary,\n",
        "            \n",
        "            g.churn,\n",
        "            \n",
        "            b.discount_number__store_coupon,\n",
        "            b.discount_value__store_coupon,\n",
        "            b.discount_number__manufacture_coupon,\n",
        "            b.discount_value__manufacture_coupon,\n",
        "            b.discount_number__misc_credit,\n",
        "            b.discount_value__misc_credit,\n",
        "            b.discount_number__prologic_credit,\n",
        "            b.discount_value__prologic_credit,\n",
        "            b.discount_number__total,\n",
        "            b.discount_value__total,\n",
        "            \n",
        "            e.deposite_number__bottle,\n",
        "            e.deposite_value__bottle,\n",
        "            e.return_number__bottle,\n",
        "            e.return_value__bottle,\n",
        "            \n",
        "            f.refund_number,\n",
        "            f.refund_value,\n",
        "            \n",
        "            c.cat_m_alco_tabacco_paid_amount_pcnt,\n",
        "            c.cat_m_baby_and_pets_paid_amount_pcnt,\n",
        "            c.cat_m_baking_paid_amount_pcnt,\n",
        "            c.cat_m_diary_paid_amount_pcnt,\n",
        "            c.cat_m_drinks_paid_amount_pcnt,\n",
        "            c.cat_m_grains_paid_amount_pcnt,\n",
        "            c.cat_m_greens_paid_amount_pcnt,\n",
        "            c.cat_m_misc_paid_amount_pcnt,\n",
        "            c.cat_m_prepared_food_paid_amount_pcnt,\n",
        "            c.cat_m_proteins_paid_amount_pcnt,\n",
        "            c.cat_m_sause_paid_amount_pcnt,\n",
        "            c.cat_m_sweets_paid_amount_pcnt,\n",
        "            \n",
        "            d.duration_since_start__months,\n",
        "            d.cards_number   \n",
        "    from rfm_features a\n",
        "    left join discount_features b\n",
        "        on a.month_id = b.month_id\n",
        "        and a.household_id = b.household_id\n",
        "    left join cat_m_portion_features c\n",
        "        on a.month_id = c.month_id\n",
        "        and a.household_id = c.household_id\n",
        "    left join loyalty_features d\n",
        "        on a.month_id = d.month_id\n",
        "        and a.household_id = d.household_id  \n",
        "    left join bottle_features e\n",
        "        on a.month_id = e.month_id\n",
        "        and a.household_id = e.household_id\n",
        "    left join refund_features f\n",
        "        on a.month_id = f.month_id\n",
        "        and a.household_id = f.household_id\n",
        "    left join churn_feature g\n",
        "        on a.month_id = g.month_id\n",
        "        and a.household_id = g.household_id\n",
        "\"\"\")\n",
        "\n",
        "features = features.fillna(0)\n",
        "features.createOrReplaceTempView('features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLiMuX5uJZPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to a file: parquet\n",
        "features.write.mode(\"overwrite\").parquet(\"universal_features_manual_cat.parquet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhetw0JiXq6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download file to local machine\n",
        "from google.colab import files\n",
        "files.download(\"universal_features_manual_cat.parquet\")   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8WXeYTdOmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}